{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "왕지영 과제 4(주석포함).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1yUKH-3IB8Q57BjtV3-WEstUd7E4aGso2",
      "authorship_tag": "ABX9TyNCfz/SvxFVCqpN6cgjuAVi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iwannamakeid/Multivariate-statistics/blob/main/%EC%99%95%EC%A7%80%EC%98%81_%EA%B3%BC%EC%A0%9C_4(%EC%A3%BC%EC%84%9D%ED%8F%AC%ED%95%A8).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2qXpOEMb1UY"
      },
      "source": [
        "# Redefining the model to be w2 * t_u ** 2 + w1 * t_u + b\n",
        "## w* t_u +b 모델과 w2 * t_u ** 2 + w1 * t_u + b 모델 비교하기\n",
        "### 변수 설명\n",
        "\n",
        "1. t_c: target data\n",
        "2. t_u: input data\n",
        "3. t_un: t_u의 정규화\n",
        "4. params: 매개변수, input 각 값에 적용되는 weight값과 bias 값을 담고 있다.\n",
        "#### 각 함수별로 사용되는 변수들은 따로 설명하겠다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJVEMLorWhPZ"
      },
      "source": [
        "#set data and tools\n",
        "\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import torch\n",
        "torch.set_printoptions(edgeitems = 2, linewidth = 75)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeWW8MQAtku5"
      },
      "source": [
        "#input datum\n",
        "\n",
        "t_c = torch.tensor([0.5, 14.0, 15.0, 28.0, 11.0,\n",
        "                    8.0, 3.0, -4.0, 6.0, 13.0, 21.0])\n",
        "t_u = torch.tensor([35.7, 55.9, 58.2, 81.9, 56.3, 48.9,\n",
        "                    33.9, 21.8, 48.4, 60.4, 68.4])\n",
        "t_un = 0.1 * t_u #입력 데이터 정규화"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0b4eU9ywNODj"
      },
      "source": [
        "# inner functions of 1-layer perceptron\n",
        "\n",
        "# basic linear model\n",
        "def model1(t_u, w, b):\n",
        "    return w*t_u + b\n",
        "\n",
        "# the given non linear model\n",
        "# add a new input and weights to model1\n",
        "def model2(t_u, w, w2, b):\n",
        "    t_u2 = t_u**2\n",
        "    return w2* t_u2 + w * t_u + b \n",
        "\n",
        "#loss functionof Mean Square Error\n",
        "def loss_fn(t_p, t_c):\n",
        "    squared_diffs = (t_p - t_c)**2\n",
        "    return squared_diffs.mean() #return the Target - Output(t_p)\n",
        "\n",
        "#spliting data into test set and validation set following the ratio of 8:2 \n",
        "def split_data(t_u):\n",
        "    n_samples = t_u.shape[0] #number of input samples\n",
        "    n_val = int(0.2 * n_samples) # set the propertation of validation set\n",
        "\n",
        "    shuffled_indices = torch.randperm(n_samples) #shuffle the order of data\n",
        "    train_indices = shuffled_indices[:-n_val]\n",
        "    val_indices = shuffled_indices[-n_val:]\n",
        "\n",
        "    return train_indices, val_indices\n",
        "\n",
        "#forward propagation that returns loss value by using model and train set\n",
        "# t_u: input data, t_c: target data, model: model name,\n",
        "# is_train: check the given data is train data\n",
        "def calc_forward(t_u, t_c,model, is_train):\n",
        "    with torch.set_grad_enabled(is_train):\n",
        "        t_p = model(t_u, *params)\n",
        "        loss = loss_fn(t_p, t_c)\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NC7TiUpsglSb"
      },
      "source": [
        "# training loop for learning\n",
        "# n_epochs: number of epoch\n",
        "# optimizer: choosen optimizer\n",
        "# params: parameters including w, b\n",
        "# model: choosen model for learning\n",
        "# train_t~, val_t: using each train and valication sets for learning \n",
        "def training_loop(n_epochs, optimizer, params, model,  train_t_u, val_t_u,train_t_c, val_t_c):\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        train_loss = calc_forward(train_t_u,train_t_c,model,True)\n",
        "        with torch.no_grad(): #no need to compute gradient in validation\n",
        "            val_loss = calc_forward(train_t_u,train_t_c,model, False)\n",
        "            assert val_loss.requires_grad == False \n",
        "        optimizer.zero_grad() #initializes gradients to zero \n",
        "        train_loss.backward() #backpropagation\n",
        "        optimizer.step() #updates weights and bias\n",
        "\n",
        "        if epoch <= 3 or epoch % 1000 == 0:\n",
        "        \n",
        "            print(f\"Epoch {epoch}, Training loss {train_loss.item():.4f},\"\n",
        "                    f\" Validation loss {val_loss.item():.4f}\")\n",
        "    return params\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqpRyGeTvVT-"
      },
      "source": [
        "#split data sets\n",
        "train_indices, val_indices = split_data(t_u)\n",
        "\n",
        "train_t_u = t_u[train_indices]\n",
        "train_t_un = t_un[train_indices]\n",
        "train_t_c = t_c[train_indices]\n",
        "\n",
        "val_t_u = t_u[val_indices]\n",
        "val_t_un = t_un[val_indices]\n",
        "val_t_c = t_c[val_indices]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iG2x0AzR5N_r"
      },
      "source": [
        "# training models\n",
        "## 변수 설명\n",
        "1. params: tensor of w,b that fits each model\n",
        "2. learning rate: learning rate used to update weights(optimizer.step)\n",
        "3. optimizer: helps training be efficient"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D02IlGGViP1q"
      },
      "source": [
        "# train model1\n",
        "params = torch.tensor([1.0, 0.0], requires_grad=True)\n",
        "learning_rate = 1e-2\n",
        "optimizer = torch.optim.SGD([params], lr=learning_rate)\n",
        "\n",
        "params1 = training_loop(3000, optimizer, params, model1, train_t_un, val_t_un,train_t_c, val_t_c)\n",
        "params1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jPGzNbHaVDE"
      },
      "source": [
        "#train model2\n",
        "# params: tensor of w1,w2, b that fits model2: w1*t_u**2 +w2+t_u + b\n",
        "params = torch.tensor([1.0,1.0, 0.0], requires_grad=True)\n",
        "learning_rate = 7e-4\n",
        "optimizer = torch.optim.SGD([params], lr=learning_rate)\n",
        "\n",
        "params2 = training_loop(10000, optimizer, params, model2,train_t_un, val_t_un,train_t_c, val_t_c)\n",
        "params2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5NbDPa-6ggb"
      },
      "source": [
        "# Visualization\n",
        "1. Compute t_p(the output data of the given model and input data)\n",
        "2. Draw a line plot set as x = input data, y = output\n",
        "3. Draw a dot plot set as x = input data, y = target\n",
        "4. Compare 2,3 to show training result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYLGcV5EYfP6"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "t_p = model1(t_un, *params1) #model(t_un, param[0], param[1])\n",
        "fig = plt.figure(dpi=600)\n",
        "plt.xlabel(\"Temperature (°Fahrenheit)\")\n",
        "plt.ylabel(\"Temperature (°Celsius)\")\n",
        "plt.plot(t_u.numpy(), t_p.detach().numpy())\n",
        "plt.plot(t_u.numpy(), t_c.numpy(), 'o')\n",
        "#plt.savefig(\"temp_unknown_plot.png\", format=\"png\") # bookskip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vdmpkPlxtS4"
      },
      "source": [
        "t_p = model2(t_un, *params2) #model(t_un, param[0], param[1], param[2])\n",
        "fig = plt.figure(dpi=500)\n",
        "plt.xlabel(\"Temperature (°Fahrenheit)\")\n",
        "plt.ylabel(\"Temperature (°Celsius)\")\n",
        "plt.plot(t_u.numpy(), t_p.detach().numpy())\n",
        "plt.plot(t_u.numpy(), t_c.numpy(), 'o')\n",
        "#plt.savefig(\"temp_unknown_plot.png\", format=\"png\") # bookskip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXAkfHkq9iJb"
      },
      "source": [
        "# 결과 분석\n",
        " 과제로 주어진 비선형 모델의 구현은 학습 데이터, 검증데이터 모두에 대한 오류가 쉽게 잡히지 않았다. 따라서 선형회귀 모델보다 학습 반복수를 크게 줘야 오류가 잡혔다. 또한 그래프로 그렸을 때, 비선형 모델이 특정 데이터 값들에 대한 오차가 선형모델보다 큰 것을 확인했다. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWwwEo8rB-WR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}